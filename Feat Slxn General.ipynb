{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf5fc1df",
   "metadata": {},
   "source": [
    "# Feature Selection - 10 Different Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d43556",
   "metadata": {},
   "source": [
    "## Imports of various datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca9262",
   "metadata": {},
   "source": [
    "### Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750a7c6",
   "metadata": {},
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data_set = 'breastcancer'\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "y = data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f5366",
   "metadata": {},
   "source": [
    "### Congress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee9327b",
   "metadata": {},
   "source": [
    "data = pd.read_csv(r'UCI/congress.csv')\n",
    "data.replace('y', 1, inplace=True)\n",
    "data.replace('n', 0, inplace=True)\n",
    "data.replace('?', 2, inplace=True)\n",
    "data.replace('republican', 1, inplace=True)\n",
    "data.replace('democrat', 0, inplace=True)\n",
    "X = data.drop(['Class Name'],axis=1)\n",
    "y = np.ravel(data['Class Name'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29257a99",
   "metadata": {},
   "source": [
    "### Heart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787f9390",
   "metadata": {},
   "source": [
    "data = pd.read_csv(f'UCI/heart.csv')\n",
    "X = data.drop(['condition'],axis=1)\n",
    "y = np.ravel(data['condition'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f9ae12",
   "metadata": {},
   "source": [
    "### Ionosphere "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b621f3a",
   "metadata": {},
   "source": [
    "data = pd.read_csv(f'UCI/ionosphere.csv')  \n",
    "X = data.drop(['class'],axis=1)\n",
    "### Must get rid of negative values\n",
    "min_values = X.iloc[:,2:].min()\n",
    "### Add the minimum value of each column to all rows in that respective column\n",
    "X.iloc[:,2:] += abs(min_values)\n",
    "X.iloc[:,2:]\n",
    "y = np.ravel(pd.get_dummies(data['class'], drop_first=True))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90211fb2",
   "metadata": {},
   "source": [
    "### Sonar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d630e6d7",
   "metadata": {},
   "source": [
    "data = pd.read_csv(f'UCI/sonar.csv')  \n",
    "X = data.drop(['Class'],axis=1)\n",
    "y = np.ravel(pd.get_dummies(data['Class'], drop_first=True))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7686eba",
   "metadata": {},
   "source": [
    "### TicTacToe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418a7cbc",
   "metadata": {},
   "source": [
    "data = pd.read_csv(f'UCI/tictactoe.csv')  \n",
    "data.replace('x', 1, inplace=True)\n",
    "data.replace('o', 0, inplace=True)\n",
    "data.replace('b', 2, inplace=True)\n",
    "data.replace('positive',1, inplace=True)\n",
    "data.replace('negative',0, inplace=True)\n",
    "X = data.drop(['V10'],axis=1)\n",
    "y = np.ravel(data['V10'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5f55f",
   "metadata": {},
   "source": [
    "### Churn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f248466",
   "metadata": {},
   "source": [
    "data_set = 'churn'\n",
    "X_train = pd.read_csv(f'UCI/{data_set}/X_train.csv')\n",
    "X_test = pd.read_csv(f'UCI/{data_set}/X_test.csv')\n",
    "y_train = pd.read_csv(f'UCI/{data_set}/y_train.csv')\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = pd.read_csv(f'UCI/{data_set}/y_test.csv')\n",
    "y_test = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effa1536",
   "metadata": {},
   "source": [
    "### For saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fc5865",
   "metadata": {},
   "source": [
    "np.savetxt(\"UCI/y_train.csv\", y_train, delimiter=\",\")\n",
    "np.savetxt(\"UCI/y_test.csv\", y_test, delimiter=\",\")\n",
    "\n",
    "X_train.to_csv('UCI/X_train.csv', index=False)\n",
    "X_test.to_csv('UCI/X_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31f688e",
   "metadata": {},
   "source": [
    "## Rationale\n",
    "\n",
    "Randomly initialized populations are cheap, but some guidance to the initial population can lead to better and faster convergence to the Pareto front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "6d8028ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pygmo as pg\n",
    "import random\n",
    "import functools\n",
    "import math as m\n",
    "import copy\n",
    "from numpy import genfromtxt\n",
    "\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn modules\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay, precision_recall_curve, recall_score\n",
    "from sklearn.metrics import make_scorer, precision_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from skfeature.function.similarity_based import fisher_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, chi2\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "import sklearn_relief as relief\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# For ignoring warnings about bad classifiers - it's the nature of the algorithm to come across these\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "import os\n",
    "\n",
    "# Matplotlib configuration\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8,6)\n",
    "plt.rcParams['figure.dpi'] = 80\n",
    "plt.rc('axes', titlesize=12)\n",
    "plt.rc('axes', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f156e",
   "metadata": {},
   "source": [
    "## Declare data set and its target. Must split into train and test, else feature selection methods use test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "a1290326",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'UCI/ionosphere.csv')  \n",
    "X = data.drop(['class'],axis=1)\n",
    "### Must get rid of negative values\n",
    "# min_values = X.iloc[:,2:].min()\n",
    "# ### Add the minimum value of each column to all rows in that respective column\n",
    "# X.iloc[:,2:] += abs(min_values)\n",
    "# X.iloc[:,2:]\n",
    "y = np.ravel(pd.get_dummies(data['class'], drop_first=True))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2c6aba",
   "metadata": {},
   "source": [
    "np.savetxt(f\"UCI/{data_set}/y_train.csv\", y_train, delimiter=\",\")\n",
    "np.savetxt(f\"UCI/{data_set}/y_test.csv\", y_test, delimiter=\",\")\n",
    "\n",
    "X_train.to_csv(f'UCI/{data_set}/X_train.csv', index=False)\n",
    "X_test.to_csv(f'UCI/{data_set}/X_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d13a567",
   "metadata": {},
   "source": [
    "### X must be a pandas dataframe with the features as columns, y must be a flat numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1adbfe3",
   "metadata": {},
   "source": [
    "## Models to run on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "95b4f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of learning algorithms\n",
    "model_dict = {\n",
    "    \"SVC lin\": SVC(random_state=42,kernel='linear',max_iter=int(1e4)),\n",
    "    \"SVC rbf\": SVC(random_state=42,kernel='rbf',max_iter=int(1e4)),\n",
    "    \"Log lasso\": LogisticRegression(random_state=42,penalty='l1', solver = 'liblinear'),\n",
    "    \"Log ridge\": LogisticRegression(random_state=42,penalty='l2'),\n",
    "    \"Dec tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Grad boost\": GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42),\n",
    "    \"Rand forest\": RandomForestClassifier(max_depth=2, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6793dede",
   "metadata": {},
   "source": [
    "### Some feature selection methods only take metric data as an input, we distinguish their keys here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "743491fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features in model\n",
    "total_features = int(X_train.shape[1])\n",
    "\n",
    "# Feature names\n",
    "feat_names = np.asarray(list(X_train.columns))\n",
    "\n",
    "# Make list of indices of all features\n",
    "feat_indices = np.asarray(list(range(total_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "78a742e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dictionary of indices of all features, for easy lookup\n",
    "feat_dictionary = {}\n",
    "\n",
    "for i, feature in enumerate(feat_names):\n",
    "    \n",
    "    feat_dictionary[feature] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30dc762",
   "metadata": {},
   "source": [
    "# Wrapper Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7672388c",
   "metadata": {},
   "source": [
    "Wrapper methods use supervised learning for selecting the optimal feature subset. They use classifiers to gauge the classification performance of the selected feature subset in every iteration. This leads to an increased computational cost than filter-based methods, but such methods also perform several times better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987c85bb",
   "metadata": {},
   "source": [
    "##  Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e2b3a2",
   "metadata": {},
   "source": [
    "RFE selects top k features based on the machine learning model that has coef_attribute or feature_importances_attribute from their model (Almost any model). RFE would eliminate the least important features then retrain the model until it only selects the K-features you want.\n",
    "\n",
    "(IMPORTANT!) This method only works if the model has coef_ or features_importances_ attribute, if there are models out there having these attributes, you could apply RFE on Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "8cda2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_feature_elimination(model_name,k):\n",
    "    '''\n",
    "    Employs the recursive feature elemination scikit-learn module to get the top k features in the training matrix\n",
    "    '''\n",
    "\n",
    "    # Selecting the best important features according to Logistic Regression\n",
    "    rfe_selector = RFE(estimator=model_dict[model_name], n_features_to_select = k, step = 1)\n",
    "\n",
    "    rfe_selector.fit(X_train, y_train)\n",
    "\n",
    "    return feat_indices[rfe_selector.get_support().tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592400d1",
   "metadata": {},
   "source": [
    "##  Feature Selection via SelectFromModel - returns many features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c9655d",
   "metadata": {},
   "source": [
    "Like the RFE, SelectFromModel from Scikit-Learn is based on a Machine Learning Model estimation for selecting the features. The differences are that SelectFromModel feature selection is based on the importance attribute (often is coef_ or feature_importances_ but it could be any callable) threshold. By default, the threshold is the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffafaada",
   "metadata": {},
   "source": [
    "SelectFromModel is a meta-transformer that can be used alongside any estimator that assigns importance to each feature through a specific attribute (such as coef_, feature_importances_) or via an importance_getter callable after fitting. The features are considered unimportant and removed if the corresponding importance of the feature values are below the provided threshold parameter. Apart from specifying the threshold numerically, there are built-in heuristics for finding a threshold using a string argument. Available heuristics are “mean”, “median” and float multiples of these like “0.1*mean”. In combination with the threshold criteria, one can use the max_features parameter to set a limit on the number of features to select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "f61945ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_from_model(model_name, k):\n",
    "    '''\n",
    "    For a given learning algorithm, get features that pass the mean threshold in the training matrix\n",
    "    '''\n",
    "\n",
    "    sfm_selector = SelectFromModel(estimator=model_dict[model_name], max_features=k)\n",
    "\n",
    "    sfm_selector.fit(X_train, y_train)\n",
    "    \n",
    "    features = np.asarray(feat_indices[sfm_selector.get_support().tolist()])\n",
    "    \n",
    "    # For handling missing values\n",
    "    if len(features) < k:\n",
    "        \n",
    "        # Get values not in the list\n",
    "        missing = feat_indices[~np.in1d(feat_indices, features)]\n",
    "        \n",
    "        # Get the number of missing features you need to add to output k\n",
    "        num_missing = k - len(features)\n",
    "        \n",
    "        return np.append(features, missing[:num_missing])\n",
    "    \n",
    "    # Add feature indices to list\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b889fe6f",
   "metadata": {},
   "source": [
    "# Filter Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438e54b3",
   "metadata": {},
   "source": [
    "Filter-based feature selection methods determine feature importance using several scoring metrics in an unsupervised fashion, requiring no classifiers in its core. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368646a1",
   "metadata": {},
   "source": [
    "## Univariate Feature Selection with SelectKBest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf4f679",
   "metadata": {},
   "source": [
    "Univariate Feature Selection is a feature selection method based on the univariate statistical test, e,g: chi2, Pearson-correlation, and many more. The first test below is done using the ANOVA F-value between label/feature for classification tasks.\n",
    "\n",
    "The premise with SelectKBest is combining the univariate statistical test with selecting the K-number of features based on the statistical result between the X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "41d4f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectkbest_ANOVA(k):\n",
    "    '''\n",
    "    Use analysis of variance to return k best features in the training matrix\n",
    "    '''\n",
    "    \n",
    "    ANOVA_selector = SelectKBest(k=k)\n",
    "\n",
    "    ANOVA_selector.fit(X_train, y_train)\n",
    "    \n",
    "    return feat_indices[ANOVA_selector.get_support().tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c7002a",
   "metadata": {},
   "source": [
    "## SelectKBest - Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e70c3e",
   "metadata": {},
   "source": [
    "From documentation: Mutual information (MI) [1] between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\n",
    "\n",
    "The function relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances as described in [2] and [3]. Both methods are based on the idea originally proposed in [4].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "92f2033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectkbest_mutual_inf(k):\n",
    "    '''\n",
    "    Use the muutal information of features to get the relative importance of k best features in the training matrix\n",
    "    '''\n",
    "    \n",
    "    MI_selector = SelectKBest(mutual_info_classif, k=k)\n",
    "\n",
    "    MI_selector.fit(X_train, y_train)\n",
    "    \n",
    "    return feat_indices[MI_selector.get_support().tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f76977e",
   "metadata": {},
   "source": [
    "## SelectKBest - ChiSquare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ab20a",
   "metadata": {},
   "source": [
    "The higher the value of the X2\n",
    "f metric, the higher is the importance of the feature f. The Chi-square measure is robust to\n",
    "the distribution of the data, can be computed with ease (i.e. low\n",
    "computational cost), and can capture detailed information from\n",
    "the data. The drawback of the method is that it is unable to interpret data classified into a large number of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "2eef28fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectkbest_chi2(k):\n",
    "    '''\n",
    "    Rank features according to chi-2 values - cannot accept negative feature values\n",
    "    '''\n",
    "    \n",
    "    chi2_selector = SelectKBest(score_func=chi2, k=k)\n",
    "\n",
    "    chi2_selector.fit(X_train, y_train)\n",
    "    \n",
    "    return np.asarray(feat_indices[chi2_selector.get_support().tolist()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d9188a",
   "metadata": {},
   "source": [
    "## Pearson Correlation Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a20814",
   "metadata": {},
   "source": [
    "A lower value of PCCx indicates higher importance of the feature x. PCC can quantify the correlation between attributes in\n",
    "the feature space since it uses the method of covariance. It measures both the magnitude and direction of association between\n",
    "the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "967b0a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_corr_select(k):\n",
    "    '''\n",
    "    Rank features according to pearson correlation co-efficient\n",
    "    '''\n",
    "\n",
    "    # Get correlations\n",
    "    correlation_matrix = np.corrcoef(X_train, y_train, rowvar=False)\n",
    "    \n",
    "    # Extract the correlation coefficients of each feature with the target (last column)\n",
    "    correlations_with_target = correlation_matrix[:-1, -1]\n",
    "    \n",
    "    # Sort the indices of the features based on the correlation coefficients in descending order\n",
    "    sorted_indices = np.argsort(correlations_with_target)[::-1]\n",
    "    \n",
    "    return sorted_indices[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c57e0e",
   "metadata": {},
   "source": [
    "## Spearman's Correlation Co-efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aa7eca",
   "metadata": {},
   "source": [
    "Spearman's rank correlation coefficient is a useful method for assessing feature importance in scenarios where the relationships between features and the response variable are not strictly linear and might involve monotonic, but not necessarily linear, trends. Unlike linear correlation measures, such as Pearson's correlation, Spearman's rank takes into account the relative order of values rather than their precise numerical differences. This makes it effective in capturing nonlinear associations and identifying features that impact the response variable in consistent monotonic ways. It is particularly valuable when dealing with ordinal or categorical data, or when the relationships involve outliers that can distort linear correlations. Spearman's rank offers a more comprehensive view of feature importance by considering both the direction and strength of monotonic relationships, making it suitable for a broader range of data distributions and relationships. This code is taken from the HFMOEA paper, (Kundu, Mallipedi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "f5146553",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def spearman_feature_importance(X, y):\n",
    "    '''\n",
    "    Use spearman rank to get feature importance of all features in data matrix\n",
    "    '''\n",
    "    \n",
    "    X = X.values\n",
    "    \n",
    "    num_features = X.shape[1]\n",
    "    feature_importance_scores = np.zeros(num_features)\n",
    "    \n",
    "    # Get spearman rank for each feature\n",
    "    for i in range(num_features):\n",
    "        feature_scores, _ = spearmanr(X[:, i], y)\n",
    "        feature_importance_scores[i] = abs(feature_scores)\n",
    "            \n",
    "    return np.argsort(feature_importance_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796e7cba",
   "metadata": {},
   "source": [
    "## Mean Absolute Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f919f9",
   "metadata": {},
   "source": [
    "The mean absolute difference (MAD) computes the absolute difference from the mean value. The main difference between the variance and MAD measures is the absence of the square in the latter. The MAD, like the variance, is also a scale variant.’ [1] This means that higher the MAD, higher the discriminatory power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "5cd37f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_abs_deviation(k):\n",
    "    '''\n",
    "    Get k best features using mean absolute deviation\n",
    "    '''\n",
    "    # Calculate MAD for each feature\n",
    "    mean_abs_diff = np.sum(np.abs(X_train - np.mean(X_train,axis=0)),axis=0)/X_train.shape[0]\n",
    "\n",
    "    # Sort by decreasing values of MAD, get the k best features\n",
    "    l = mean_abs_diff.to_frame().sort_values(by=[0], ascending=False)\n",
    "    k_best_strings = list(l.index[:k])\n",
    "\n",
    "    return np.asarray([feat_dictionary[el] for el in k_best_strings])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e9e82",
   "metadata": {},
   "source": [
    "## Fisher Score - metric vars only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d93746",
   "metadata": {},
   "source": [
    "Input only metric features. Fisher score is one of the most widely used supervised feature selection methods. The algorithm which we will use returns the ranks of the variables based on the fisher’s score in descending order. We can then select the variables as per the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "6d914fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_score_func(k):\n",
    "    '''\n",
    "    Select best k features using fisher score\n",
    "    '''\n",
    "    # Use the Fisher algorithm to get a score for each metric feature\n",
    "    ranks = fisher_score.fisher_score(X_train.values,y_train)\n",
    "    \n",
    "    return np.asarray(ranks[:k])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47180f41",
   "metadata": {},
   "source": [
    "## Relief Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385b6f51",
   "metadata": {},
   "source": [
    "A\n",
    "similarity-based metric that computes the Euclidean distance to\n",
    "assert feature importance. For this, a feature X is selected randomly, and its two nearest neighbors, based on the Euclidean\n",
    "distance, are selected as such: one from the same class as X, represented as H, called nearest hit, and the other neighbor from a\n",
    "different class, represented as M, called nearest miss. \n",
    "\n",
    "The Relief filter methods do not assume conditional independence of the features in the feature space to estimate their\n",
    "importance, unlike many heuristic algorithms. Relief is an efficient algorithm that can capture contextual information and\n",
    "assess the attribute quality in cases where there are strong dependences between the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "492ea2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relief(k):\n",
    "    '''\n",
    "    Use relief algorithm to get feature rankings for k top features\n",
    "    '''\n",
    "\n",
    "    r = relief.Relief(\n",
    "        n_features=total_features\n",
    "    ) \n",
    "\n",
    "    my_transformed_matrix = r.fit_transform(\n",
    "        X_train.values,\n",
    "        y_train\n",
    "    )\n",
    "\n",
    "    # Higher weights are better\n",
    "    weights = np.zeros((total_features ,2))\n",
    "\n",
    "    weights[:,0], weights[:,1] = np.asarray(r.w_), feat_indices\n",
    "\n",
    "    weights_sort = weights[weights[:, 0].argsort()[::-1]]\n",
    "\n",
    "    return np.asarray(weights_sort[:k,1].astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2111aaf",
   "metadata": {},
   "source": [
    "# Building a Borda voting system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801a73c3",
   "metadata": {},
   "source": [
    "### Declare model name to run for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "05204446",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Log lasso'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55c53dc",
   "metadata": {},
   "source": [
    "### Method names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "5f201679",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = ['PCC', 'MAD', 'Fisher', 'Relief', 'RFE', 'SFM', 'ANOVA', 'MI', 'Chi-2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5294c36",
   "metadata": {},
   "source": [
    "### Check if every function returns the right amount of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef663158",
   "metadata": {},
   "source": [
    "k = total_features\n",
    "elements_list = [\n",
    "    pearson_corr_select(k),\n",
    "    mean_abs_deviation(k),\n",
    "    fisher_score_func(k),\n",
    "    Relief(k),\n",
    "    recursive_feature_elimination(model_name, k),\n",
    "    select_from_model(model_name, k),\n",
    "    selectkbest_ANOVA(k),\n",
    "    selectkbest_mutual_inf(k),\n",
    "    selectkbest_chi2(k)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00708fb",
   "metadata": {},
   "source": [
    "print(\"Missing features in each method are as follows:\")\n",
    "for i, el in enumerate(elements_list):\n",
    "    \n",
    "    missing = len(feat_indices[~np.in1d(feat_indices, el)])\n",
    "    \n",
    "    if missing > 0:\n",
    "        print(f\"Method {method_names[i]} has {missing} missing features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dada45",
   "metadata": {},
   "source": [
    "# Methods that return ranked lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710fcaab",
   "metadata": {},
   "source": [
    "### A function that returns the best features from feature selection methods that rank their outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51e8ec0",
   "metadata": {},
   "source": [
    "For example, the relief algorithm does return a score for each feature, allowing for very easy ranking. But some selection methods return only the k features they selected in numerical order. So in order to get a ranking from every one, this process is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "83199f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranked_features():\n",
    "    '''\n",
    "    This function returns a ranked list of features from all the methods listed in it\n",
    "    '''\n",
    "    \n",
    "    features = []\n",
    "    k = total_features\n",
    "    \n",
    "    features.append(spearman_feature_importance(X_train,y_train))\n",
    "    features.append(pearson_corr_select(k))\n",
    "    features.append(mean_abs_deviation(k))\n",
    "    features.append(fisher_score_func(k))\n",
    "    features.append(Relief(k))\n",
    "    \n",
    "    return np.asarray(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3890f3b7",
   "metadata": {},
   "source": [
    "# Methods that don't return ranked lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da13ae0",
   "metadata": {},
   "source": [
    "### A function that returns the best features from feature selection methods that don't rank their outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "9bf50abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_for_k(k, model_name):\n",
    "    '''\n",
    "    Used recursively with incremented k to build a ranking list for feature selection methods that don't\n",
    "    return featuers in order they are ranked in\n",
    "    '''\n",
    "    \n",
    "    features=[]\n",
    "    try:\n",
    "        features.append(recursive_feature_elimination(model_name,k))\n",
    "        features.append(select_from_model(model_name, k))\n",
    "        features.append(selectkbest_ANOVA(k))\n",
    "        features.append(selectkbest_mutual_inf(k))\n",
    "        features.append(selectkbest_chi2(k))\n",
    "    \n",
    "    except ValueError:\n",
    "        features.append(recursive_feature_elimination(model_name,k))\n",
    "        features.append(select_from_model(model_name, k))\n",
    "        features.append(selectkbest_ANOVA(k))\n",
    "        features.append(selectkbest_mutual_inf(k))\n",
    "\n",
    "    return np.asarray(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b06330",
   "metadata": {},
   "source": [
    "### A function to append only the unique features output by each iteration of k to the matrix of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "e91b6eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_unique_elements_column(matrix1, matrix2):\n",
    "    '''\n",
    "    Adds unique feature indices found with each iteration of k to the rankings matrix\n",
    "    '''\n",
    "    # Initialize an empty array to store the new column\n",
    "    new_column = np.empty((matrix1.shape[0], 1), dtype=matrix1.dtype)\n",
    "\n",
    "    # Iterate through the rows of both matrices\n",
    "    for i in range(matrix1.shape[0]):\n",
    "        # Find the unique elements in the corresponding row of matrix2\n",
    "        unique_elements = np.setdiff1d(matrix2[i], matrix1[i])\n",
    "\n",
    "        # Add the first unique element to the new column\n",
    "        new_column[i, 0] = unique_elements[0]\n",
    "\n",
    "    # Concatenate the new column to matrix1\n",
    "    result_matrix = np.hstack((matrix1, new_column))\n",
    "\n",
    "    return result_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9b662",
   "metadata": {},
   "source": [
    "### A function that combines the above two to produce a matrix of features, where each method represents a row and each column represents a ranking of the features, with an index of 0 being best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "c8bf4a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_matrix():\n",
    "    '''\n",
    "    Calls all function necessary to build feature matrix\n",
    "    '''\n",
    "    \n",
    "    ranked = get_ranked_features()\n",
    "    \n",
    "    output = get_features_for_k(1, model_name)\n",
    "    \n",
    "    for k in range(2,total_features+1):\n",
    "    \n",
    "        matrix2 = get_features_for_k(k, model_name)\n",
    "\n",
    "        output = add_unique_elements_column(output, matrix2)\n",
    "\n",
    "    return np.vstack((ranked, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "84fe0901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4916: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/numpy/lib/function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/Tomm/opt/anaconda3/envs/ORwDS_light/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "rankings_matrix = get_feature_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95e8ad2",
   "metadata": {},
   "source": [
    "## Calculating and plotting Borda scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "e15ffb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_borda_scores(rankings_matrix, weights=None):\n",
    "    '''\n",
    "    I: ranking matrix from get_feature_matrix\n",
    "    I (optional) weights, array of floats from zero to one, represent the voting weight that particular feature selection method has\n",
    "    O: borda scores for all features in the data matrix\n",
    "    '''\n",
    "    num_features = len(rankings_matrix[0])\n",
    "    num_methods = len(rankings_matrix)\n",
    "    borda_scores = np.zeros(num_features)\n",
    "\n",
    "    if weights is None:\n",
    "        weights = np.ones(num_methods)\n",
    "\n",
    "    if len(weights) != num_methods:\n",
    "        raise ValueError(\"The number of weights must be equal to the number of methods.\")\n",
    "\n",
    "    for i, method_rankings in enumerate(rankings_matrix):\n",
    "        try:\n",
    "            # Calculate the scores for each feature based on its ranking in the method and apply weights\n",
    "            scores = weights[i] * (num_features - np.array(method_rankings))\n",
    "            borda_scores += scores\n",
    "        except ValueError as e:\n",
    "            print(\"Error:\", e)\n",
    "            print(\"Ensure that all feature rankings have the same number of features.\")\n",
    "            return None\n",
    "\n",
    "    return borda_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "6556b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.31412219, 0.86978109, 0.02877184, 0.25149087, 0.05472679,\n",
    "       0.77189679, 0.7694783 , 0.94683922, 0.41915218, 0.0572985 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "e36612dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Index</th>\n",
       "      <th>Borda Score</th>\n",
       "      <th>Feature Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>320</td>\n",
       "      <td>a12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>315</td>\n",
       "      <td>a03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>288</td>\n",
       "      <td>a19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>281</td>\n",
       "      <td>a34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>277</td>\n",
       "      <td>a15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>260</td>\n",
       "      <td>a20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>a04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>a02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>253</td>\n",
       "      <td>a06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature Index  Borda Score Feature Name\n",
       "11             11          320          a12\n",
       "2               2          315          a03\n",
       "0               0          310          a01\n",
       "18             18          288          a19\n",
       "33             33          281          a34\n",
       "14             14          277          a15\n",
       "19             19          260          a20\n",
       "3               3          258          a04\n",
       "1               1          255          a02\n",
       "5               5          253          a06"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the Borda count scores for each feature\n",
    "borda_scores = calculate_borda_scores(rankings_matrix, None)\n",
    "\n",
    "# Create a DataFrame to organize the results\n",
    "results_df = pd.DataFrame({\n",
    "    \"Feature Index\": range(len(borda_scores)),\n",
    "    \"Borda Score\": [int(score) for score in borda_scores],\n",
    "    \"Feature Name\": [feat_names[i] for i in range(len(borda_scores))]\n",
    "})\n",
    "\n",
    "# Sort the DataFrame based on the Borda scores in descending order\n",
    "results_df = results_df.sort_values(by=\"Borda Score\", ascending=False)\n",
    "\n",
    "# Display the first ten scores\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6570426",
   "metadata": {},
   "source": [
    "### For saving things"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2ccc94",
   "metadata": {},
   "source": [
    "np.savetxt(\"rankings_matrix.csv\", rankings_matrix, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e384a5",
   "metadata": {},
   "source": [
    "results_df.to_csv('borda_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "9c9aa56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 960x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming you have a DataFrame called 'df' with columns 'Feature Index', 'Borda Score', and 'Feature Name'\n",
    "# Sort the DataFrame by 'Borda Score' in descending order\n",
    "df_sorted = results_df.sort_values(by='Borda Score', ascending=False)\n",
    "\n",
    "# Partition the features into 3 sets based on the sorted Borda scores\n",
    "num_features = len(df_sorted)\n",
    "num_features_per_set = num_features // 3\n",
    "set1 = df_sorted.iloc[:num_features_per_set]\n",
    "set2 = df_sorted.iloc[num_features_per_set:2*num_features_per_set]\n",
    "set3 = df_sorted.iloc[2*num_features_per_set:]\n",
    "\n",
    "# Create the bar plot with different colors for each set\n",
    "plt.figure(figsize=(12, 6))  # Adjust the figure size as per your requirement\n",
    "\n",
    "plt.bar(set1['Feature Name'], set1['Borda Score'], color='darkgreen', label='$\\mathcal{B}$')\n",
    "plt.bar(set2['Feature Name'], set2['Borda Score'], color='cornflowerblue', label='$\\mathcal{G}$')\n",
    "plt.bar(set3['Feature Name'], set3['Borda Score'], color='firebrick', label='$\\mathcal{W}$')\n",
    "\n",
    "# Set x-axis labels with rotation for better visibility\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Set axis labels and title\n",
    "plt.ylabel('Borda Score')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"borda_scores_vodafone.pdf\", bbox_inches='tight', format=\"pdf\", dpi=1200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b6967",
   "metadata": {},
   "source": [
    "## Partition Borda scores, save as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "bb041c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_borda_scores(borda_scores):\n",
    "    '''\n",
    "    Partitions feature set into three equal sets based on Borda scores\n",
    "    '''\n",
    "    # Get the feature indices sorted based on Borda scores (in descending order)\n",
    "    sorted_indices = sorted(range(len(borda_scores)), key=lambda x: borda_scores[x], reverse=True)\n",
    "\n",
    "    # Calculate the size of each set (best, good, worst) to achieve roughly equal partitions\n",
    "    set_size = len(sorted_indices) // 3\n",
    "    remaining = len(sorted_indices) % 3\n",
    "\n",
    "    # Partition the indices into three sets\n",
    "    best_features = sorted_indices[:set_size + remaining]\n",
    "    good_features = sorted_indices[set_size + remaining: 2 * (set_size + remaining)]\n",
    "    worst_features = sorted_indices[2 * (set_size + remaining):]\n",
    "\n",
    "    psi = [best_features,good_features,worst_features]\n",
    "\n",
    "    ordered = [np.unique(feat_set) for feat_set in psi]\n",
    "\n",
    "    return ordered[0], ordered[1], ordered[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "b832cbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features, good_features, worst_features = partition_borda_scores(borda_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "73f19717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices in order\n",
    "\n",
    "psi = [best_features,good_features,worst_features]\n",
    "\n",
    "ordered = [np.unique(feat_set) for feat_set in psi]\n",
    "    \n",
    "np.savetxt(f\"UCI/{data_set}/best.csv\", ordered[0], delimiter=\",\")\n",
    "np.savetxt(f\"UCI/{data_set}/good.csv\", ordered[1], delimiter=\",\")\n",
    "np.savetxt(f\"UCI/{data_set}/worst.csv\", ordered[2], delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b79038",
   "metadata": {},
   "source": [
    "## Showing all partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "7eec750f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This workbook found this many best features: 12 \n",
      "\n",
      "These are the indices of the best features: [0, 1, 2, 3, 5, 11, 13, 14, 15, 18, 19, 33] \n",
      "\n",
      "These are the feature names of the best features: ['a01' 'a02' 'a03' 'a04' 'a06' 'a12' 'a14' 'a15' 'a16' 'a19' 'a20' 'a34']\n"
     ]
    }
   ],
   "source": [
    "print(f\"This workbook found this many best features: {len(best_features)} \\n\")\n",
    "print(f\"These are the indices of the best features: {list(best_features)} \\n\")\n",
    "print(f\"These are the feature names of the best features: {feat_names[best_features]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "2dca095c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This workbook found this many unique good features: 12 \n",
      "\n",
      "These are the indices of the good features: [ 4  8  9 10 20 21 22 23 26 28 29 31] \n",
      "\n",
      "These are the feature names of the good features: ['a05' 'a09' 'a10' 'a11' 'a21' 'a22' 'a23' 'a24' 'a27' 'a29' 'a30' 'a32']\n"
     ]
    }
   ],
   "source": [
    "print(f\"This workbook found this many unique good features: {len(good_features)} \\n\")\n",
    "print(f\"These are the indices of the good features: {good_features} \\n\")\n",
    "print(f\"These are the feature names of the good features: {feat_names[good_features]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "4460e4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This workbook found this many unique worst features: 10 \n",
      "\n",
      "These are the indices of the worst features: [ 6  7 12 16 17 24 25 27 30 32] \n",
      "\n",
      "These are the feature names of the worst features: ['a07' 'a08' 'a13' 'a17' 'a18' 'a25' 'a26' 'a28' 'a31' 'a33']\n"
     ]
    }
   ],
   "source": [
    "print(f\"This workbook found this many unique worst features: {len(worst_features)} \\n\")\n",
    "print(f\"These are the indices of the worst features: {worst_features} \\n\")\n",
    "print(f\"These are the feature names of the worst features: {feat_names[worst_features]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
